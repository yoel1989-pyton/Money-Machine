"""
============================================================








































































































































































































































































































































































































































































































































































































































































































}  ]    }      "updatedAt": "2025-01-01T00:00:00.000Z"      "createdAt": "2025-01-01T00:00:00.000Z",      "name": "Money-Machine",    {    },      "updatedAt": "2025-01-01T00:00:00.000Z"      "createdAt": "2025-01-01T00:00:00.000Z",      "name": "Self-Healing",    {    },      "updatedAt": "2025-01-01T00:00:00.000Z"      "createdAt": "2025-01-01T00:00:00.000Z",      "name": "Elite",    {  "tags": [  },    "instanceId": "elite-money-machine-v1"    "templateCredsSetupCompleted": false,  "meta": {  "pinData": {},  "staticData": null,  },    "errorWorkflow": "error-trigger-global"    "callerPolicy": "workflowsFromSameOwner",    "saveManualExecutions": true,    "executionOrder": "v1",  "settings": {  },    }      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ”„ Self-Improvement Logic",          {        [      "main": [    "ğŸš€ Expansion Engine": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸš€ Expansion Engine",          {        [      "main": [    "ğŸ“Š Performance Analyzer": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“Š Performance Analyzer",          {        [      "main": [    "ğŸ“ˆ Analytics Scan (6hr)": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“± Success Alert",          {        [      "main": [    "ğŸ“‹ Log to Airtable": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“‹ Log to Airtable",          {        [      "main": [    "ğŸ§¬ DNA Extractor": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ§¬ DNA Extractor",          {        [      "main": [    "ğŸ“º YouTube Upload": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“º YouTube Upload",          {        [      "main": [    "ğŸ“Š YouTube Metadata": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "âš ï¸ Partial Alert",          {        [        ],          }            "index": 0            "type": "main",            "node": "ğŸ“Š YouTube Metadata",          {        [      "main": [    "âœ… Quality Gate": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "âœ… Quality Gate",          {        [      "main": [    "ğŸ“¦ Asset Aggregator": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“¦ Asset Aggregator",          {        [      "main": [    "ğŸ¨ Leonardo Visuals": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“¦ Asset Aggregator",          {        [      "main": [    "â˜ï¸ Save Audio to Drive": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "â˜ï¸ Save Audio to Drive",          {        [      "main": [    "ğŸ™ï¸ ElevenLabs Voice": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ¨ Leonardo Visuals",          {          },            "index": 0            "type": "main",            "node": "ğŸ™ï¸ ElevenLabs Voice",          {        [      "main": [    "âš¡ Script Processor": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "âš¡ Script Processor",          {        [      "main": [    "ğŸ“ Elite Script Architect": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“ Elite Script Architect",          {        [      "main": [    "ğŸ§  AAVE Brain - Topic Selector": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ§  AAVE Brain - Topic Selector",          {        [      "main": [    "ğŸ¯ Manual Trigger": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ§  AAVE Brain - Topic Selector",          {        [      "main": [    "ğŸ’“ 30min Heartbeat": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "ğŸ“± Alert to Phone",          {        [      "main": [    "âš¡ Error Intelligence": {    },      ]        ]          }            "index": 0            "type": "main",            "node": "âš¡ Error Intelligence",          {        [      "main": [    "ğŸš¨ Global Error Handler": {  "connections": {  ],    }      "position": [1000, 900]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ”„ Self-Improvement Logic",      "id": "self-improvement",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ”„ SELF-IMPROVEMENT ENGINE - Mutation Based on Performance\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// This is the AAVE mutation logic that evolves the content strategy\n\nconst mutationEngine = {\n  mutation_rules: [\n    {\n      condition: 'AVD < 50%',\n      action: 'STRENGTHEN_HOOK',\n      adjustment: 'Increase pattern interrupt intensity in first 3 seconds'\n    },\n    {\n      condition: 'CTR < 3%',\n      action: 'OPTIMIZE_THUMBNAIL',\n      adjustment: 'Test high-contrast colors and facial expressions'\n    },\n    {\n      condition: 'Engagement < 3%',\n      action: 'ADD_CONTROVERSY',\n      adjustment: 'Increase provocative statements and open loops'\n    },\n    {\n      condition: 'RPM < $0.03',\n      action: 'SHIFT_NICHE',\n      adjustment: 'Move toward higher CPM topics (investing > budgeting)'\n    }\n  ],\n  learning_window: '7 days',\n  mutation_frequency: 'Weekly',\n  genetic_inheritance: 'Winners pass DNA to next generation of content'\n};\n\nreturn [{ json: mutationEngine }];"      "parameters": {    {    },      "position": [700, 900]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸš€ Expansion Engine",      "id": "expansion-engine",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸš€ EXPANSION DECISION ENGINE - Shorts â†’ Documentary\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// This node would receive winner data and decide on expansion\n\nconst expansionProtocol = {\n  expansion_type: 'DOCUMENTARY',\n  target_duration: '10-15 minutes',\n  act_structure: [\n    'ACT 1: Hook (Shorts DNA - first 60 seconds)',\n    'ACT 2: Historical Context',\n    'ACT 3: The Hidden Mechanism',\n    'ACT 4: Global Impact',\n    'ACT 5: Resolution & Call to Action'\n  ],\n  production_specs: {\n    resolution: '3840x2160',\n    bitrate: '18M',\n    audio_quality: 'studio_dry',\n    visual_style: 'ken_burns_parallax'\n  },\n  trigger_conditions: 'AVD > 75% AND RPM > $0.05 AND Views > 1000'\n};\n\nreturn [{ json: expansionProtocol }];"      "parameters": {    {    },      "position": [400, 900]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ“Š Performance Analyzer",      "id": "performance-analyzer",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ“ˆ PERFORMANCE ANALYZER - Identify Winners for Expansion\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst WINNER_THRESHOLDS = {\n  min_avd: 75,          // Average View Duration %\n  min_rpm: 0.05,        // Revenue per 1000 views\n  min_views: 1000,      // Minimum views to qualify\n  min_engagement: 5     // Engagement rate %\n};\n\n// This would normally fetch from YouTube Analytics API\n// For now, it returns the analysis framework\n\nconst analysisFramework = {\n  thresholds: WINNER_THRESHOLDS,\n  scan_time: new Date().toISOString(),\n  action: 'SCAN_FOR_WINNERS',\n  next_steps: [\n    'Fetch recent videos from Airtable DNA log',\n    'Query YouTube Analytics for each video',\n    'Compare metrics against thresholds',\n    'Flag winners for longform expansion',\n    'Update DNA records with performance data'\n  ]\n};\n\nreturn [{ json: analysisFramework }];"      "parameters": {    {    },      "position": [100, 900]      "typeVersion": 1.2,      "type": "n8n-nodes-base.scheduleTrigger",      "name": "ğŸ“ˆ Analytics Scan (6hr)",      "id": "analytics-trigger",      },        }          ]            }              "hoursInterval": 6              "field": "hours",            {          "interval": [        "rule": {      "parameters": {    {    },      "waitBetweenTries": 5000      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Telegram Bot"          "id": "TELEGRAM_CRED_ID",        "telegramApi": {      "credentials": {      "position": [2300, 700],      "typeVersion": 1.2,      "type": "n8n-nodes-base.telegram",      "name": "âš ï¸ Partial Alert",      "id": "partial-notify",      },        }          "parse_mode": "Markdown"        "additionalFields": {        "text": "=âš ï¸ **PARTIAL GENERATION**\n\nğŸ¯ Topic: {{ $json.topic }}\n\n**Missing Assets:**\n{{ $json.pipeline.missing_assets.join(', ') || 'Unknown' }}\n\nğŸ”§ The system will retry on next cycle.\n\n**Available:**\n- Script: {{ $json.script?.word_count || 0 }} words\n- Audio: {{ $json.audio?.drive_link ? 'âœ…' : 'âŒ' }}\n- Visuals: {{ $json.visuals?.images?.length || 0 }} images",        "chatId": "={{ $env.TELEGRAM_CHAT_ID }}",      "parameters": {    {    },      "waitBetweenTries": 5000      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Telegram Bot"          "id": "TELEGRAM_CRED_ID",        "telegramApi": {      "credentials": {      "position": [3100, 400],      "typeVersion": 1.2,      "type": "n8n-nodes-base.telegram",      "name": "ğŸ“± Success Alert",      "id": "success-notify",      },        }          "parse_mode": "Markdown"        "additionalFields": {        "text": "=âœ… **CONTENT PUBLISHED**\n\nğŸ“¹ **{{ $node['ğŸ“Š YouTube Metadata'].json.title }}**\n\nğŸ”— {{ $node['ğŸ§¬ DNA Extractor'].json.video_url || 'Processing...' }}\n\nğŸ“Š **Stats:**\n- Words: {{ $node['ğŸ“Š YouTube Metadata'].json.assets.script.word_count }}\n- Archetype: {{ $node['ğŸ“Š YouTube Metadata'].json.assets.archetype }}\n\nâ±ï¸ Uploaded: {{ $node['ğŸ§¬ DNA Extractor'].json.uploaded_at }}",        "chatId": "={{ $env.TELEGRAM_CHAT_ID }}",      "parameters": {    {    },      "waitBetweenTries": 5000      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Airtable Token"          "id": "AIRTABLE_CRED_ID",        "airtableTokenApi": {      "credentials": {      "position": [2900, 400],      "typeVersion": 2.1,      "type": "n8n-nodes-base.airtable",      "name": "ğŸ“‹ Log to Airtable",      "id": "airtable-log",      },        "options": {}        },          "value": {}          "mappingMode": "autoMapInputData",        "columns": {        },          "mode": "name"          "value": "Content DNA",          "__rl": true,        "sheetName": {        },          "mode": "id"          "value": "={{ $env.AIRTABLE_BASE_ID }}",          "__rl": true,        "documentId": {        "operation": "append",      "parameters": {    {    },      "position": [2700, 400]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ§¬ DNA Extractor",      "id": "dna-extractor",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ§¬ DNA EXTRACTION - Learn from this execution\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst metadata = $node['ğŸ“Š YouTube Metadata'].json || {};\nconst uploadResult = $input.all()[0]?.json || {};\n\nconst dnaRecord = {\n  // Video identification\n  video_id: uploadResult.id || 'pending',\n  video_url: uploadResult.id ? `https://youtube.com/shorts/${uploadResult.id}` : null,\n  \n  // Content DNA\n  topic: metadata.assets?.topic,\n  archetype: metadata.assets?.archetype,\n  visual_intent: metadata.assets?.visuals?.visual_intent,\n  word_count: metadata.assets?.script?.word_count,\n  \n  // Tracking fields (to be updated by analytics workflow)\n  metrics: {\n    views: 0,\n    retention_rate: null,\n    rpm: null,\n    engagement_rate: null\n  },\n  \n  // Status\n  uploaded_at: new Date().toISOString(),\n  status: uploadResult.id ? 'PUBLISHED' : 'PENDING_UPLOAD',\n  expansion_eligible: false, // Set to true when metrics exceed threshold\n  \n  // Execution tracking\n  execution_id: $execution?.id\n};\n\nreturn [{ json: dnaRecord }];"      "parameters": {    {    },      "onError": "continueRegularOutput"      "waitBetweenTries": 10000,      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "YouTube OAuth"          "id": "YOUTUBE_CRED_ID",        "youTubeOAuth2Api": {      "credentials": {      "position": [2500, 400],      "typeVersion": 1,      "type": "n8n-nodes-base.youTube",      "name": "ğŸ“º YouTube Upload",      "id": "youtube-upload",      },        }          "tags": "={{ $json.tags.join(',') }}"          "privacyStatus": "={{ $json.privacy }}",        "options": {        "description": "={{ $json.description }}",        "title": "={{ $json.title }}",        "resource": "video",      "parameters": {    {    },      "position": [2300, 400]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ“Š YouTube Metadata",      "id": "youtube-metadata",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ“Š YOUTUBE METADATA GENERATOR - SEO Optimized\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst assets = $input.all()[0]?.json || {};\n\nconst HASHTAGS = {\n  system_reveal: '#money #wealth #financialfreedom #investing #richvsrich',\n  hidden_mechanism: '#taxes #economy #inflation #finance #truth',\n  lifestyle_hack: '#savemoney #budgeting #personalfinance #moneytips',\n  psychology_reveal: '#psychology #mindset #wealthmindset #success',\n  conspiracy_lite: '#system #middleclass #economy #awakening',\n  urgency_narrative: '#wealthtransfer #opportunity #investing #now'\n};\n\nconst POWER_WORDS = ['SECRET', 'HIDDEN', 'EXPOSED', 'TRUTH', 'REALITY', 'REVEALED'];\n\nfunction generateTitle(topic, archetype) {\n  const powerWord = POWER_WORDS[Math.floor(Math.random() * POWER_WORDS.length)];\n  const templates = [\n    `${topic} (${powerWord})`,\n    `The ${powerWord} About ${topic.split(' ').slice(-3).join(' ')}`,\n    `${topic} - What They Don't Tell You`\n  ];\n  return templates[Math.floor(Math.random() * templates.length)];\n}\n\nfunction generateDescription(topic, script) {\n  const preview = script?.substring(0, 150) || '';\n  return `${preview}...\n\nğŸ”” Subscribe for more wealth secrets\n\n${HASHTAGS[assets.archetype] || '#money #finance'}\n\nâš ï¸ This is educational content only. Not financial advice.`;\n}\n\nconst youtubeMetadata = {\n  title: generateTitle(assets.topic, assets.archetype),\n  description: generateDescription(assets.topic, assets.script?.optimized),\n  tags: [\n    'money', 'wealth', 'finance', 'investing', 'rich',\n    'financial freedom', 'passive income', 'money tips',\n    assets.archetype?.replace('_', ' '),\n    ...assets.visuals?.asset_keywords || []\n  ].filter(Boolean),\n  category: '22', // People & Blogs\n  privacy: 'public',\n  madeForKids: false,\n  assets: assets\n};\n\nreturn [{ json: youtubeMetadata }];"      "parameters": {    {    },      "position": [2100, 500]      "typeVersion": 2,      "type": "n8n-nodes-base.if",      "name": "âœ… Quality Gate",      "id": "quality-gate",      },        }          ]            }              }                "operation": "equals"                "type": "string",              "operator": {              "rightValue": "COMPLETE",              "leftValue": "={{ $json.pipeline.status }}",              "id": "pipeline-status",            {          "conditions": [          },            "typeValidation": "strict"            "leftValue": "",            "caseSensitive": true,          "options": {        "conditions": {      "parameters": {    {    },      "position": [1900, 500]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ“¦ Asset Aggregator",      "id": "asset-aggregator",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ¬ ASSET AGGREGATOR - Combine all generated assets\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst scriptData = $node['âš¡ Script Processor'].json || {};\nconst audioData = $node['â˜ï¸ Save Audio to Drive'].json || {};\nconst visualData = $node['ğŸ¨ Leonardo Visuals'].json || {};\n\n// Validate critical assets\nconst hasAudio = audioData.id || audioData.webViewLink;\nconst hasVisuals = visualData.generations?.length > 0 || visualData.generatedImages?.length > 0;\n\nif (!hasAudio) {\n  console.log('âš ï¸ WARNING: Audio generation may have failed');\n}\n\n// Build comprehensive asset package\nconst assetPackage = {\n  // Content metadata\n  topic: scriptData.topic,\n  archetype: scriptData.archetype,\n  content_type: scriptData.content_type,\n  \n  // Script assets\n  script: {\n    raw: scriptData.script_raw,\n    optimized: scriptData.script_optimized,\n    word_count: scriptData.word_count,\n    duration_estimate: scriptData.estimated_duration_seconds\n  },\n  \n  // Audio assets\n  audio: {\n    drive_id: audioData.id || null,\n    drive_link: audioData.webViewLink || null,\n    download_link: audioData.webContentLink || null,\n    filename: audioData.name || null\n  },\n  \n  // Visual assets\n  visuals: {\n    images: visualData.generations || visualData.generatedImages || [],\n    visual_intent: scriptData.visual_intent,\n    asset_keywords: scriptData.visual_assets\n  },\n  \n  // Pipeline metadata\n  pipeline: {\n    generated_at: new Date().toISOString(),\n    execution_id: $execution?.id,\n    status: hasAudio && hasVisuals ? 'COMPLETE' : 'PARTIAL',\n    missing_assets: []\n      .concat(!hasAudio ? ['audio'] : [])\n      .concat(!hasVisuals ? ['visuals'] : [])\n  }\n};\n\nreturn [{ json: assetPackage }];"      "parameters": {    {    },      "onError": "continueRegularOutput"      "waitBetweenTries": 15000,      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Leonardo API"          "id": "LEONARDO_CRED_ID",        "httpHeaderAuth": {      "credentials": {      "position": [1300, 600],      "typeVersion": 4.2,      "type": "n8n-nodes-base.httpRequest",      "name": "ğŸ¨ Leonardo Visuals",      "id": "visual-generator",      },        }          "timeout": 180000        "options": {        "jsonBody": "={\n  \"prompt\": \"Cinematic {{ $node['âš¡ Script Processor'].json.visual_assets[0] || 'finance' }} scene, dark moody lighting, 8k resolution, film grain, dramatic shadows, professional photography, {{ $node['âš¡ Script Processor'].json.visual_intent }} aesthetic\",\n  \"negative_prompt\": \"text, watermark, low quality, blurry, cartoon, anime\",\n  \"modelId\": \"6bef9f1b-29cb-40c7-b9df-32b51c1f67d3\",\n  \"width\": 1080,\n  \"height\": 1920,\n  \"num_images\": 4,\n  \"guidance_scale\": 7\n}",        "specifyBody": "json",        "sendBody": true,        "genericAuthType": "httpHeaderAuth",        "authentication": "genericCredentialType",        "url": "https://api.leonardo.ai/v1/generations",        "method": "POST",      "parameters": {    {    },      "waitBetweenTries": 5000      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Google Drive"          "id": "GDRIVE_CRED_ID",        "googleDriveOAuth2Api": {      "credentials": {      "position": [1600, 400],      "typeVersion": 3,      "type": "n8n-nodes-base.googleDrive",      "name": "â˜ï¸ Save Audio to Drive",      "id": "drive-upload-audio",      },        "options": {}        "folderId": "={{ $env.GOOGLE_DRIVE_FOLDER_ID }}",        "name": "={{ $node['âš¡ Script Processor'].json.topic.replace(/[^a-zA-Z0-9]/g, '_') }}_{{ Date.now() }}.mp3",        "operation": "upload",      "parameters": {    {    },      "onError": "continueRegularOutput"      "waitBetweenTries": 10000,      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "ElevenLabs API"          "id": "ELEVENLABS_CRED_ID",        "httpHeaderAuth": {      "credentials": {      "position": [1300, 400],      "typeVersion": 4.2,      "type": "n8n-nodes-base.httpRequest",      "name": "ğŸ™ï¸ ElevenLabs Voice",      "id": "voice-generator",      },        }          "timeout": 120000          },            }              "responseFormat": "file"            "response": {          "response": {        "options": {        "jsonBody": "={\n  \"text\": \"{{ $json.script_optimized }}\",\n  \"model_id\": \"eleven_multilingual_v2\",\n  \"voice_settings\": {\n    \"stability\": 0.5,\n    \"similarity_boost\": 0.8,\n    \"style\": 0.4,\n    \"use_speaker_boost\": true\n  }\n}",        "specifyBody": "json",        "sendBody": true,        "genericAuthType": "httpHeaderAuth",        "authentication": "genericCredentialType",        "url": "https://api.elevenlabs.io/v1/text-to-speech/={{ $env.ELEVENLABS_VOICE_ID }}",        "method": "POST",      "parameters": {    {    },      "position": [1000, 400]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "âš¡ Script Processor",      "id": "script-processor",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ™ï¸ VOICE GENERATION ORCHESTRATOR\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.all()[0]?.json || {};\nconst previousData = $node['ğŸ§  AAVE Brain - Topic Selector'].json || {};\n\nconst script = input.message?.content || input.text || '';\n\nif (!script || script.length < 50) {\n  throw new Error('SCRIPT_TOO_SHORT: Generated script is invalid or empty');\n}\n\n// Clean and optimize script for TTS\nfunction optimizeForTTS(text) {\n  return text\n    .replace(/\\n{2,}/g, ' ... ')  // Natural pauses\n    .replace(/\\*\\*/g, '')          // Remove markdown\n    .replace(/[#_]/g, '')          // Remove formatting\n    .replace(/\\s+/g, ' ')          // Normalize whitespace\n    .trim();\n}\n\nconst optimizedScript = optimizeForTTS(script);\nconst wordCount = optimizedScript.split(/\\s+/).length;\nconst estimatedDuration = Math.ceil(wordCount / 2.5); // ~150 words/min\n\nreturn [{\n  json: {\n    topic: previousData.topic,\n    archetype: previousData.archetype,\n    visual_intent: previousData.visual_intent,\n    visual_assets: previousData.visual_assets,\n    script_raw: script,\n    script_optimized: optimizedScript,\n    word_count: wordCount,\n    estimated_duration_seconds: estimatedDuration,\n    content_type: estimatedDuration <= 60 ? 'SHORT' : 'LONGFORM',\n    generation_timestamp: new Date().toISOString()\n  }\n}];"      "parameters": {    {    },      "onError": "continueRegularOutput"      "waitBetweenTries": 5000,      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "OpenAI API"          "id": "OPENAI_CRED_ID",        "openAiApi": {      "credentials": {      "position": [700, 400],      "typeVersion": 1.4,      "type": "@n8n/n8n-nodes-langchain.openAi",      "name": "ğŸ“ Elite Script Architect",      "id": "script-generator",      },        }          "maxTokens": 400          "temperature": 0.8,        "options": {        },          ]            }              "content": "=Write a 60-second viral script about: {{ $json.topic }}\n\nArchetype: {{ $json.archetype }}\nVisual Intent: {{ $json.visual_intent }}"              "role": "user",            {            },              "content": "You are an elite YouTube Shorts scriptwriter specializing in finance/wealth content. Your scripts are designed for MAXIMUM retention:\n\n**HOOK FORMULA (First 3 seconds):**\n- Pattern interrupt (shocking stat/question)\n- Direct address (\"You're being...\")\n- Controversy trigger\n\n**STRUCTURE:**\n1. HOOK (0-3s): Pattern interrupt\n2. PROBLEM (3-15s): Agitate the pain\n3. MECHANISM (15-35s): The hidden \"how\"\n4. PAYOFF (35-50s): The revelation\n5. CTA (50-60s): Engagement trigger\n\n**VOICE:**\n- Authoritative but accessible\n- Short punchy sentences\n- Rhetorical questions\n- Power words: \"secret\", \"hidden\", \"rigged\", \"exposed\"\n\nOutput ONLY the script. No titles, no labels, no timestamps. Pure narration text."              "role": "system",            {          "values": [        "messages": {        "model": "gpt-4o",      "parameters": {    {    },      "position": [400, 400]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "ğŸ§  AAVE Brain - Topic Selector",      "id": "aave-brain",      },        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ğŸ§  AAVE INTELLIGENCE ENGINE - Topic Selection & DNA Extraction\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst ELITE_TOPIC_POOL = [\n  // SYSTEM REVEALS (Kiyosaki Framework)\n  { topic: \"Why the Rich Use Debt as a Weapon\", archetype: \"system_reveal\", visual_intent: \"power_finance\", priority: 95 },\n  { topic: \"The Hidden Tax That Steals Your Wealth\", archetype: \"hidden_mechanism\", visual_intent: \"surveillance\", priority: 92 },\n  { topic: \"Why Banks Want You Broke\", archetype: \"system_reveal\", visual_intent: \"corporate_power\", priority: 90 },\n  { topic: \"The 3 Money Lies They Teach in School\", archetype: \"education_expose\", visual_intent: \"deception\", priority: 88 },\n  \n  // LIFESTYLE ARBITRAGE (Graham Stephan Framework)\n  { topic: \"How I Save 50% of My Income Automatically\", archetype: \"lifestyle_hack\", visual_intent: \"wealth_building\", priority: 87 },\n  { topic: \"The Credit Card Hack Banks Hate\", archetype: \"system_exploit\", visual_intent: \"financial_hack\", priority: 85 },\n  { topic: \"Why Your Savings Account is Losing Money\", archetype: \"hidden_loss\", visual_intent: \"inflation_visual\", priority: 84 },\n  \n  // PSYCHOLOGY (Andrei Jikh Framework)\n  { topic: \"The Psychology of Why You Stay Poor\", archetype: \"psychology_reveal\", visual_intent: \"human_behavior\", priority: 91 },\n  { topic: \"Why the Middle Class is Disappearing by Design\", archetype: \"conspiracy_lite\", visual_intent: \"systems_control\", priority: 93 },\n  { topic: \"The Wealth Transfer Happening Right Now\", archetype: \"urgency_narrative\", visual_intent: \"economic_shift\", priority: 89 }\n];\n\nconst VISUAL_DNA_MAP = {\n  power_finance: [\"skyscrapers\", \"vaults\", \"dark_boardrooms\", \"luxury_suits\"],\n  surveillance: [\"cameras\", \"data_streams\", \"government_buildings\", \"documents\"],\n  corporate_power: [\"wall_street\", \"bank_buildings\", \"money_stacks\", \"contracts\"],\n  deception: [\"masks\", \"shadows\", \"fine_print\", \"manipulation\"],\n  wealth_building: [\"compound_growth\", \"real_estate\", \"investment_charts\", \"passive_income\"],\n  financial_hack: [\"credit_cards\", \"points\", \"travel\", \"rewards\"],\n  inflation_visual: [\"shrinking_dollar\", \"price_tags\", \"grocery_costs\", \"fed_building\"],\n  human_behavior: [\"brain_scans\", \"decision_making\", \"crowd_psychology\", \"emotions\"],\n  systems_control: [\"chess_pieces\", \"puppet_strings\", \"class_divide\", \"policy_documents\"],\n  economic_shift: [\"wealth_gap\", \"market_crashes\", \"opportunity_zones\", \"timing\"]\n};\n\n// Select topic using weighted randomization favoring high priority\nfunction selectEliteTopic() {\n  const totalWeight = ELITE_TOPIC_POOL.reduce((sum, t) => sum + t.priority, 0);\n  let random = Math.random() * totalWeight;\n  \n  for (const topic of ELITE_TOPIC_POOL) {\n    random -= topic.priority;\n    if (random <= 0) {\n      return {\n        ...topic,\n        visual_assets: VISUAL_DNA_MAP[topic.visual_intent] || [],\n        selected_at: new Date().toISOString(),\n        execution_id: $execution?.id || 'manual'\n      };\n    }\n  }\n  return { ...ELITE_TOPIC_POOL[0], visual_assets: VISUAL_DNA_MAP[ELITE_TOPIC_POOL[0].visual_intent] };\n}\n\nconst selected = selectEliteTopic();\n\nreturn [{ json: selected }];"      "parameters": {    {    },      "webhookId": "money-machine-trigger"      "position": [100, 500],      "typeVersion": 2,      "type": "n8n-nodes-base.webhook",      "name": "ğŸ¯ Manual Trigger",      "id": "webhook-trigger",      },        "options": {}        "genericAuthType": "httpHeaderAuth",        "authentication": "genericCredentialType",        "url": "={{ $env.WEBHOOK_MANUAL_TRIGGER }}",        "method": "POST",      "parameters": {    {    },      "position": [100, 300]      "typeVersion": 1.2,      "type": "n8n-nodes-base.scheduleTrigger",      "name": "ğŸ’“ 30min Heartbeat",      "id": "heartbeat-trigger",      },        }          ]            }              "minutesInterval": 30              "field": "minutes",            {          "interval": [        "rule": {      "parameters": {    {    },      "waitBetweenTries": 5000      "maxTries": 3,      "retryOnFail": true,      },        }          "name": "Telegram Bot"          "id": "TELEGRAM_CRED_ID",        "telegramApi": {      "credentials": {      "position": [2800, -200],      "typeVersion": 1.2,      "type": "n8n-nodes-base.telegram",      "name": "ğŸ“± Alert to Phone",      "id": "error-notify-telegram",      },        }          "parse_mode": "Markdown"        "additionalFields": {        "text": "=ğŸš¨ **MONEY MACHINE ALERT**\n\n**Severity:** {{ $json.severity }}\n**Node:** {{ $json.node_failed }}\n**Type:** {{ $json.error_type }}\n**Time:** {{ $json.timestamp }}\n\n**Message:**\n```{{ $json.message }}```\n\n**Recovery:** {{ $json.recovery_action }}\n\nğŸ”— [View Execution]({{ $env.N8N_URL }}/execution/{{ $json.execution_id }})",        "chatId": "={{ $env.TELEGRAM_CHAT_ID }}",      "parameters": {    {    },      "position": [2600, -200]      "typeVersion": 2,      "type": "n8n-nodes-base.code",      "name": "âš¡ Error Intelligence",      "id": "error-processor",      },        "jsCode": "// ELITE ERROR PROCESSOR - Extract actionable intelligence\nconst error = $input.all()[0]?.json || {};\nconst executionId = $execution?.id || 'unknown';\nconst workflowName = $workflow?.name || 'Money Machine';\nconst timestamp = new Date().toISOString();\n\n// Build forensic error report\nconst errorReport = {\n  severity: error.message?.includes('rate limit') ? 'WARN' : 'CRITICAL',\n  execution_id: executionId,\n  workflow: workflowName,\n  timestamp: timestamp,\n  node_failed: error.node?.name || 'Unknown Node',\n  error_type: error.message?.includes('timeout') ? 'TIMEOUT' : \n              error.message?.includes('401') ? 'AUTH_FAILURE' :\n              error.message?.includes('429') ? 'RATE_LIMIT' :\n              error.message?.includes('500') ? 'API_DOWN' : 'UNKNOWN',\n  message: error.message || 'No message',\n  stack: error.stack?.substring(0, 500) || 'No stack',\n  recovery_action: getRecoveryAction(error)\n};\n\nfunction getRecoveryAction(err) {\n  if (err.message?.includes('rate limit') || err.message?.includes('429')) {\n    return 'AUTO_RETRY_DELAYED';\n  }\n  if (err.message?.includes('timeout')) {\n    return 'AUTO_RETRY_IMMEDIATE';\n  }\n  if (err.message?.includes('401') || err.message?.includes('403')) {\n    return 'CHECK_CREDENTIALS';\n  }\n  return 'MANUAL_REVIEW';\n}\n\nreturn [{ json: errorReport }];"      "parameters": {    {    },      "position": [2400, -200]      "typeVersion": 1,      "type": "n8n-nodes-base.errorTrigger",      "name": "ğŸš¨ Global Error Handler",      "id": "error-trigger-global",      "parameters": {},    {  "nodes": [MONEY MACHINE - QUALITY GATES ENGINE
Elite Pre-Upload Validation & Channel Protection
============================================================
NEVER upload broken content. Quarantine instead.
============================================================
"""

import os
import re
import json
import asyncio
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple, List
import unicodedata

# ============================================================
# CONFIGURATION
# ============================================================

class QualityConfig:
    """Quality Gate Configuration - NON-NEGOTIABLE"""
    
    # Video requirements
    MIN_DURATION = 30  # seconds
    MAX_DURATION = 58  # seconds (Shorts limit)
    MIN_FRAME_COUNT = 300  # ~10 seconds at 30fps
    # Black frame detection only catches TRUE black (0x000000)
    # Consistent dark backgrounds (purple, blue) are ACCEPTABLE
    # Only fail on INTERMITTENT black frames (5-95% range)
    MAX_BLACK_FRAME_RATIO = 0.95  # Allow consistent backgrounds
    
    # Audio requirements
    # TTS naturally has 15-25% silence between sentences - this is NORMAL
    # Only fail if silence is abnormally high (>35% = broken TTS)
    MAX_SILENCE_RATIO = 0.35  # 35% - allows natural sentence pauses
    MIN_AUDIO_PEAK_DB = -6.0  # dB
    MAX_AUDIO_PEAK_DB = -1.0  # dB
    MAX_PAUSE_DURATION_MS = 300  # milliseconds
    
    # TTS requirements
    MIN_WORDS_PER_SENTENCE = 3
    MAX_WORDS_PER_SENTENCE = 18
    
    # ğŸ›¡ï¸ FILE INTEGRITY REQUIREMENTS (Blocking Authority)
    MIN_SHORT_SIZE_MB = 15  # Elite 8Mbps Short must be >15MB
    MIN_LONGFORM_SIZE_MB = 100  # Documentary must be >100MB
    
    # Paths
    BASE_DIR = Path(__file__).parent.parent
    QUARANTINE_DIR = BASE_DIR / "data" / "quarantine"
    
    # Safe Mode channels (production only, no experiments)
    SAFE_MODE_CHANNELS = [
        "UCZppwcvPrWlAG0vb78elPJA",  # Money machine ai
    ]


# ============================================================
# ğŸ›¡ï¸ FILE INTEGRITY GUARD (Blocking Authority Fix)
# ============================================================

def validate_file_integrity(file_path: str, content_type: str = "SHORT") -> Tuple[bool, dict]:
    """
    Blocks uploads of corrupted/partial renders.
    This is the FINAL gate before any upload.
    
    Args:
        file_path: Path to video file
        content_type: "SHORT" or "LONGFORM"
    
    Returns:
        (passed, report) - Whether file passes integrity check
    """
    report = {
        "file_path": file_path,
        "content_type": content_type,
        "passed": False,
        "errors": []
    }
    
    if not os.path.exists(file_path):
        report["errors"].append("FILE_NOT_FOUND")
        return False, report
    
    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
    report["file_size_mb"] = round(file_size_mb, 2)
    
    # Size thresholds based on content type
    min_size = QualityConfig.MIN_SHORT_SIZE_MB if content_type == "SHORT" else QualityConfig.MIN_LONGFORM_SIZE_MB
    
    if file_size_mb < min_size:
        report["errors"].append(f"FILE_TOO_SMALL: {file_size_mb:.2f}MB < {min_size}MB minimum")
        print(f"ğŸš« [GATE] Integrity FAILED: {file_size_mb:.2f}MB is too small. Suspected corruption.")
        return False, report
    
    # Verify video is playable using ffprobe
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration,bit_rate",
             "-of", "json", file_path],
            capture_output=True, text=True, timeout=30
        )
        
        if result.returncode != 0:
            report["errors"].append("FFPROBE_FAILED: Cannot read video metadata")
            return False, report
        
        probe_data = json.loads(result.stdout)
        duration = float(probe_data.get("format", {}).get("duration", 0))
        bitrate = int(probe_data.get("format", {}).get("bit_rate", 0))
        
        report["duration_seconds"] = round(duration, 2)
        report["bitrate_mbps"] = round(bitrate / 1_000_000, 2)
        
        # Verify duration is reasonable
        if content_type == "SHORT" and (duration < 10 or duration > 65):
            report["errors"].append(f"DURATION_INVALID: {duration:.1f}s not in 10-65s range")
            return False, report
        
        # Verify bitrate meets minimum
        if bitrate < 2_000_000:  # 2 Mbps minimum
            report["errors"].append(f"BITRATE_TOO_LOW: {bitrate/1_000_000:.2f} Mbps < 2 Mbps")
            return False, report
            
    except Exception as e:
        report["errors"].append(f"PROBE_ERROR: {str(e)}")
        return False, report
    
    report["passed"] = True
    print(f"ğŸ’ [GATE] Integrity Verified: {file_size_mb:.2f}MB @ {report['bitrate_mbps']}Mbps")
    return True, report


# ============================================================
# SCRIPT SANITIZER (FIX 1 & 2)
# ============================================================

class ScriptSanitizer:
    """
    Sanitizes scripts BEFORE TTS to prevent robotic pauses.
    This is the PRIMARY fix for word-by-word TTS.
    """
    
    # Emoji pattern
    EMOJI_PATTERN = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "\U0001f926-\U0001f937"
        "\U00010000-\U0010ffff"
        "\u2640-\u2642"
        "\u2600-\u2B55"
        "\u200d"
        "\u23cf"
        "\u23e9"
        "\u231a"
        "\ufe0f"
        "\u3030"
        "]+", 
        flags=re.UNICODE
    )
    
    @staticmethod
    def sanitize_for_tts(text: str) -> str:
        """
        Clean text for TTS - removes all causes of robotic pauses.
        """
        if not text:
            return ""
        
        # Step 1: Remove emojis
        text = ScriptSanitizer.EMOJI_PATTERN.sub(' ', text)
        
        # Step 2: Remove bullet points and list markers
        text = re.sub(r'^[\s]*[-â€¢â—â—‹â—†â–ªâ–¸â–º\*\d+\.]+\s*', '', text, flags=re.MULTILINE)
        
        # Step 3: Replace line breaks with spaces
        text = re.sub(r'\n+', ' ', text)
        
        # Step 4: Remove excessive whitespace
        text = re.sub(r'\s+', ' ', text)
        
        # Step 5: Remove ALL CAPS words (replace with title case)
        def fix_caps(match):
            word = match.group(0)
            if len(word) > 2 and word.isupper():
                return word.title()
            return word
        text = re.sub(r'\b[A-Z]{3,}\b', fix_caps, text)
        
        # Step 6: Remove [PAUSE] markers and other brackets
        text = re.sub(r'\[.*?\]', '', text)
        text = re.sub(r'\{.*?\}', '', text)
        
        # Step 7: Remove hashtags from spoken text
        text = re.sub(r'#\w+', '', text)
        
        # Step 8: Remove URLs
        text = re.sub(r'http\S+', '', text)
        
        # Step 9: Clean up punctuation spacing
        text = re.sub(r'\s+([.,!?])', r'\1', text)
        text = re.sub(r'([.,!?])([A-Za-z])', r'\1 \2', text)
        
        # Step 10: Final trim
        text = text.strip()
        
        return text
    
    @staticmethod
    def split_into_sentences(text: str) -> List[str]:
        """
        Split text into proper sentences for TTS.
        Ensures each sentence is 3-18 words.
        """
        # First sanitize
        text = ScriptSanitizer.sanitize_for_tts(text)
        
        # Split on sentence boundaries
        raw_sentences = re.split(r'(?<=[.!?])\s+', text)
        
        result = []
        buffer = []
        
        for sentence in raw_sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            words = sentence.split()
            word_count = len(words)
            
            if word_count < QualityConfig.MIN_WORDS_PER_SENTENCE:
                # Too short - add to buffer
                buffer.extend(words)
                if len(buffer) >= QualityConfig.MIN_WORDS_PER_SENTENCE:
                    result.append(' '.join(buffer))
                    buffer = []
            elif word_count > QualityConfig.MAX_WORDS_PER_SENTENCE:
                # Too long - split into chunks
                if buffer:
                    result.append(' '.join(buffer))
                    buffer = []
                    
                chunks = []
                current_chunk = []
                for word in words:
                    current_chunk.append(word)
                    if len(current_chunk) >= 12:  # Target ~12 words per chunk
                        chunks.append(' '.join(current_chunk))
                        current_chunk = []
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                result.extend(chunks)
            else:
                # Just right
                if buffer:
                    result.append(' '.join(buffer))
                    buffer = []
                result.append(sentence)
        
        # Don't forget the buffer
        if buffer:
            if result:
                # Merge with last sentence if short
                result[-1] = result[-1] + ' ' + ' '.join(buffer)
            else:
                result.append(' '.join(buffer))
        
        return result
    
    @staticmethod
    def prepare_for_tts(text: str) -> str:
        """
        Prepare final text for TTS with proper sentence structure.
        """
        sentences = ScriptSanitizer.split_into_sentences(text)
        # Join with periods and spaces for natural TTS flow
        return '. '.join(s.rstrip('.!?') for s in sentences if s) + '.'


# ============================================================
# TTS PROSODY SETTINGS (FIX 3)
# ============================================================

class TTSProsody:
    """
    Locked TTS prosody settings for human-like speech.
    """
    
    # Default settings (LOCKED for production)
    DEFAULT = {
        "rate": "+8%",      # Slightly faster = more engaging
        "pitch": "+2Hz",    # Slightly higher = more energetic
    }
    
    # Safe mode settings (for protected channels)
    SAFE_MODE = {
        "rate": "+6%",      # Conservative
        "pitch": "+1Hz",    # Conservative
    }
    
    # Voice presets (verified to sound human)
    VERIFIED_VOICES = [
        "en-US-ChristopherNeural",  # Male US - Good for finance
        "en-US-GuyNeural",          # Male US - Authoritative
        "en-US-JennyNeural",        # Female US - Friendly
    ]
    
    @staticmethod
    def get_settings(channel_id: str = None) -> dict:
        """Get TTS settings based on channel."""
        if channel_id in QualityConfig.SAFE_MODE_CHANNELS:
            return TTSProsody.SAFE_MODE
        return TTSProsody.DEFAULT
    
    @staticmethod
    def is_voice_verified(voice_id: str) -> bool:
        """Check if voice is verified for production."""
        return voice_id in TTSProsody.VERIFIED_VOICES


# ============================================================
# VIDEO QUALITY VALIDATOR (FIX 4 & 5)
# ============================================================

class VideoValidator:
    """
    Validates video before upload.
    Blocks broken content from ever being uploaded.
    """
    
    @staticmethod
    async def get_video_info(video_path: str) -> dict:
        """Get comprehensive video information using ffprobe."""
        cmd = [
            "ffprobe",
            "-v", "error",
            "-select_streams", "v:0",
            "-count_packets",
            "-show_entries", "stream=width,height,r_frame_rate,nb_read_packets,codec_type",
            "-show_entries", "format=duration,size",
            "-of", "json",
            video_path
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, _ = await process.communicate()
            return json.loads(stdout.decode())
        except:
            return {}
    
    @staticmethod
    async def get_audio_info(video_path: str) -> dict:
        """Get audio stream information."""
        cmd = [
            "ffprobe",
            "-v", "error",
            "-select_streams", "a:0",
            "-show_entries", "stream=codec_type,sample_rate,channels",
            "-of", "json",
            video_path
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, _ = await process.communicate()
            return json.loads(stdout.decode())
        except:
            return {}
    
    @staticmethod
    async def check_black_frames(video_path: str) -> float:
        """
        Check ratio of TRUE black frames in video.
        Only catches actual black (0x000000), not dark colors.
        Returns ratio from 0.0 to 1.0
        """
        cmd = [
            "ffmpeg",
            "-i", video_path,
            # pix_th=0.02 = only catch frames that are 98%+ black
            # This allows dark backgrounds like purple/blue
            "-vf", "blackdetect=d=0.1:pix_th=0.02",
            "-an",
            "-f", "null",
            "-"
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()
            output = stderr.decode()
            
            # Parse black frame durations
            black_duration = 0.0
            for match in re.finditer(r'black_duration:(\d+\.?\d*)', output):
                black_duration += float(match.group(1))
            
            # Get total duration
            total_match = re.search(r'Duration: (\d+):(\d+):(\d+\.?\d*)', output)
            if total_match:
                h, m, s = total_match.groups()
                total_duration = int(h) * 3600 + int(m) * 60 + float(s)
                return black_duration / total_duration if total_duration > 0 else 1.0
            
            return 0.0
        except:
            return 0.0
    
    @staticmethod
    async def check_silence(video_path: str) -> float:
        """
        Check ratio of silence in audio.
        Returns ratio from 0.0 to 1.0
        """
        cmd = [
            "ffmpeg",
            "-i", video_path,
            "-af", "silencedetect=n=-40dB:d=0.3",
            "-f", "null",
            "-"
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()
            output = stderr.decode()
            
            # Parse silence durations
            silence_duration = 0.0
            for match in re.finditer(r'silence_duration: (\d+\.?\d*)', output):
                silence_duration += float(match.group(1))
            
            # Get total duration
            total_match = re.search(r'Duration: (\d+):(\d+):(\d+\.?\d*)', output)
            if total_match:
                h, m, s = total_match.groups()
                total_duration = int(h) * 3600 + int(m) * 60 + float(s)
                return silence_duration / total_duration if total_duration > 0 else 1.0
            
            return 0.0
        except:
            return 0.0
    
    @staticmethod
    async def validate(video_path: str) -> Tuple[bool, List[str]]:
        """
        Full video validation - ENHANCED to catch audio-only files.
        Returns (passed, list_of_errors)
        """
        errors = []
        
        if not os.path.exists(video_path):
            return False, ["Video file does not exist"]
        
        # Get video info
        video_info = await VideoValidator.get_video_info(video_path)
        audio_info = await VideoValidator.get_audio_info(video_path)
        
        # Check 1: Video stream exists
        video_streams = video_info.get("streams", [])
        if not video_streams:
            errors.append("NO VIDEO STREAM - Audio only file")
            return False, errors  # FAIL IMMEDIATELY for audio-only
        
        # Check 2: Video dimensions are valid (NON-ZERO)
        video_stream = video_streams[0]
        width = int(video_stream.get("width", 0))
        height = int(video_stream.get("height", 0))
        
        if width == 0 or height == 0:
            errors.append(f"INVALID VIDEO DIMENSIONS - width={width}, height={height}")
            return False, errors  # FAIL IMMEDIATELY
        
        # Check 3: Frame count is sufficient (HARD REQUIREMENT)
        frame_count = int(video_stream.get("nb_read_packets", 0))
        if frame_count < QualityConfig.MIN_FRAME_COUNT:
            errors.append(f"INSUFFICIENT FRAMES - {frame_count} frames < {QualityConfig.MIN_FRAME_COUNT} required (likely audio-only)")
            return False, errors  # FAIL IMMEDIATELY
        
        # Check 4: Audio stream exists
        audio_streams = audio_info.get("streams", [])
        if not audio_streams:
            errors.append("NO AUDIO STREAM - Silent video")
        
        # Check 5: Duration in range
        format_info = video_info.get("format", {})
        duration = float(format_info.get("duration", 0))
        
        if duration < QualityConfig.MIN_DURATION:
            errors.append(f"Duration too short: {duration:.1f}s < {QualityConfig.MIN_DURATION}s")
        if duration > QualityConfig.MAX_DURATION:
            errors.append(f"Duration too long: {duration:.1f}s > {QualityConfig.MAX_DURATION}s")
        
        # Check 6: Black frames
        # SMART LOGIC: Only fail on INTERMITTENT black frames (5-95%)
        # 0% or 100% = consistent visuals = ACCEPTABLE
        # This allows solid color backgrounds (purple, blue) to pass
        black_ratio = await VideoValidator.check_black_frames(video_path)
        if 0.05 < black_ratio < 0.95:  # Intermittent = broken
            errors.append(f"Intermittent black frames: {black_ratio*100:.1f}% (broken video)")
        
        # Check 7: Silence
        # TTS naturally has 15-25% silence between sentences - this is NORMAL
        silence_ratio = await VideoValidator.check_silence(video_path)
        if silence_ratio > QualityConfig.MAX_SILENCE_RATIO:
            errors.append(f"Too much silence: {silence_ratio*100:.1f}% > {QualityConfig.MAX_SILENCE_RATIO*100}%")
        
        passed = len(errors) == 0
        return passed, errors


# ============================================================
# QUALITY GATE (MASTER CONTROLLER)
# ============================================================

class QualityGate:
    """
    Master quality gate that blocks all broken content.
    This is the final checkpoint before upload.
    """
    
    def __init__(self):
        self.quarantine_dir = QualityConfig.QUARANTINE_DIR
        self.quarantine_dir.mkdir(parents=True, exist_ok=True)
    
    async def check_video(self, video_path: str, channel_id: str = None) -> Tuple[bool, dict]:
        """
        Run all quality checks on a video.
        Returns (can_upload, report)
        """
        report = {
            "video_path": video_path,
            "channel_id": channel_id,
            "timestamp": datetime.utcnow().isoformat(),
            "checks": {},
            "passed": False,
            "errors": []
        }
        
        # Safe mode check
        safe_mode = channel_id in QualityConfig.SAFE_MODE_CHANNELS
        report["safe_mode"] = safe_mode
        
        # Run validation
        passed, errors = await VideoValidator.validate(video_path)
        report["checks"]["video_validation"] = {
            "passed": passed,
            "errors": errors
        }
        report["errors"].extend(errors)
        
        report["passed"] = passed
        
        if not passed:
            # Move to quarantine
            await self.quarantine(video_path, report)
        
        return passed, report
    
    async def quarantine(self, video_path: str, report: dict):
        """
        Move failed video to quarantine folder.
        """
        if not os.path.exists(video_path):
            return
        
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = os.path.basename(video_path)
        
        # Move video
        quarantine_video = self.quarantine_dir / f"{timestamp}_{filename}"
        os.rename(video_path, quarantine_video)
        
        # Save report
        report_path = self.quarantine_dir / f"{timestamp}_{filename}.report.json"
        with open(report_path, "w") as f:
            json.dump(report, f, indent=2)
        
        print(f"[QUALITY] âŒ Video quarantined: {quarantine_video}")
        print(f"[QUALITY] Errors: {report['errors']}")
    
    def check_script(self, script: str) -> Tuple[bool, str]:
        """
        Validate and sanitize a script.
        Returns (valid, sanitized_script)
        """
        sanitized = ScriptSanitizer.prepare_for_tts(script)
        
        # Check if anything remains
        if len(sanitized.strip()) < 20:
            return False, ""
        
        return True, sanitized
    
    def get_tts_settings(self, channel_id: str = None) -> dict:
        """Get TTS settings for a channel."""
        return TTSProsody.get_settings(channel_id)
    
    def is_safe_mode_channel(self, channel_id: str) -> bool:
        """Check if channel is in safe mode."""
        return channel_id in QualityConfig.SAFE_MODE_CHANNELS


# ============================================================
# VISUAL FALLBACK ENGINE (FIX 5)
# ============================================================

class VisualFallback:
    """
    Provides guaranteed visual content when stock footage fails.
    NEVER allows audio-only or black-screen uploads.
    """
    
    BASE_DIR = Path(__file__).parent.parent
    ASSETS_DIR = BASE_DIR / "data" / "assets"
    
    @staticmethod
    async def create_gradient_background(output_path: str, duration: float = 60) -> bool:
        """
        Create an animated gradient background as fallback.
        Uses a purple-blue gradient (wealth/money aesthetic).
        """
        # Use color source with gradient filter that actually works
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi",
            "-i", f"color=c=0x4a0080:s=1080x1920:d={duration}",  # Purple base
            "-vf", 
            "geq=r='clip(r(X,Y)*1.2+Y*0.05,0,255)':"
            "g='clip(g(X,Y)*0.5+Y*0.02,0,255)':"
            "b='clip(b(X,Y)*1.0+X*0.03,0,255)',"
            "zoompan=z='1.0+0.05*sin(on/30)':d=1:s=1080x1920",
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-crf", "23",
            "-t", str(duration),
            output_path
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()
            
            # If geq fails, use simple solid color with zoom
            if process.returncode != 0:
                # Fallback: Simple bright purple with zoom effect
                cmd_simple = [
                    "ffmpeg", "-y",
                    "-f", "lavfi",
                    "-i", f"color=c=0x6b21a8:s=1080x1920:d={duration}",  # Bright purple
                    "-vf", "zoompan=z='1.0+0.02*sin(on/30)':d=1:s=1080x1920",
                    "-c:v", "libx264",
                    "-preset", "ultrafast",
                    "-crf", "23",
                    "-t", str(duration),
                    output_path
                ]
                process2 = await asyncio.create_subprocess_exec(
                    *cmd_simple,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await process2.communicate()
                return process2.returncode == 0
            
            return True
        except:
            return False
    
    @staticmethod
    async def create_kinetic_text_background(
        output_path: str,
        text: str = "MONEY MACHINE",
        duration: float = 60
    ) -> bool:
        """
        Create a kinetic text animation as fallback.
        """
        # Escape text for FFmpeg
        escaped_text = text.replace("'", "\\'").replace(":", "\\:")
        
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi",
            "-i", f"color=c=black:s=1080x1920:d={duration}",
            "-vf", f"drawtext=text='{escaped_text}':fontsize=80:fontcolor=white:x=(w-text_w)/2+sin(t*2)*50:y=(h-text_h)/2+cos(t*2)*30",
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-crf", "23",
            "-t", str(duration),
            output_path
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await process.communicate()
            return process.returncode == 0
        except:
            return False
    
    @staticmethod
    async def get_fallback_background(duration: float = 60, script: str = None) -> str:
        """
        Get background video matched to script content.
        Tries in order:
        1. REAL B-roll matched to visual_intent (ELITE)
        2. REAL B-roll from any category
        3. Existing default_bg.mp4
        4. Create gradient (LAST RESORT)
        """
        import random
        import os
        from engines.broll_engine import BRollEngine, resolve_visual_intent
        
        # PRIORITY 1: Use B-roll engine with visual intent matching
        try:
            engine = BRollEngine()
            
            if script:
                # ELITE: Match B-roll to script content
                intent = resolve_visual_intent(script)
                clip = await engine.get_clip_for_intent(intent)
                if clip:
                    return clip
            
            # Fallback: Any real B-roll
            clip = await engine.get_random_clip()
            if clip:
                print(f"[VISUAL] Using REAL B-roll: {Path(clip).name}")
                return clip
        except Exception as e:
            print(f"[VISUAL] B-roll engine error: {e}")
        
        # PRIORITY 2: Manual search of backgrounds folder
        backgrounds_dir = VisualFallback.ASSETS_DIR / "backgrounds"
        if backgrounds_dir.exists():
            real_videos = []
            for root, dirs, files in os.walk(backgrounds_dir):
                # Skip deprecated/synthetic folders
                if "_deprecated" in root or "synthetic" in root.lower():
                    continue
                for f in files:
                    if f.endswith(('.mp4', '.mov', '.webm')):
                        real_videos.append(os.path.join(root, f))
            
            if real_videos:
                selected = random.choice(real_videos)
                print(f"[VISUAL] Using REAL B-roll: {Path(selected).name}")
                return selected
        
        # FALLBACK 3: Check for existing default
        default_bg = VisualFallback.ASSETS_DIR / "default_bg.mp4"
        if default_bg.exists():
            return str(default_bg)
        
        # FALLBACK 4: Create assets directory and gradient (LAST RESORT)
        print("[VISUAL] âš ï¸ No real B-roll found, creating gradient fallback")
        VisualFallback.ASSETS_DIR.mkdir(parents=True, exist_ok=True)
        
        # Try gradient
        gradient_path = str(VisualFallback.ASSETS_DIR / "fallback_gradient.mp4")
        if await VisualFallback.create_gradient_background(gradient_path, duration):
            return gradient_path
        
        # Try kinetic text
        kinetic_path = str(VisualFallback.ASSETS_DIR / "fallback_kinetic.mp4")
        if await VisualFallback.create_kinetic_text_background(kinetic_path, "ğŸ’°", duration):
            return kinetic_path
        
        # Last resort - create a simple bright color background (NOT DARK)
        color_path = str(VisualFallback.ASSETS_DIR / "fallback_color.mp4")
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi",
            "-i", f"color=c=0x6b21a8:s=1080x1920:d={duration}",  # Bright purple
            "-c:v", "libx264",
            "-preset", "ultrafast",
            color_path
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        await process.communicate()
        
        return color_path


# ============================================================
# EXPORT ALL
# ============================================================

__all__ = [
    "QualityConfig",
    "ScriptSanitizer",
    "TTSProsody",
    "VideoValidator",
    "QualityGate",
    "VisualFallback"
]
